{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOGUDhQvEhgX2GhwGWIzoXf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JuneWayne/RAG-Based-Chatbot-Demo/blob/main/Colab_Inline_RAG_Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG Based chabot demo"
      ],
      "metadata": {
        "id": "oIaDuL04aHbi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple chatbot with RetrievalQA"
      ],
      "metadata": {
        "id": "fle1kT_edQez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain openai chromadb tiktoken pypdf\n",
        "!pip install -U langchain-community\n",
        "import os\n",
        "import tempfile\n",
        "\n",
        "import panel as pn\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "L6c2iaCTaFYa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['OPENAI_API_KEY'] = ''\n",
        "\n",
        "loader = PyPDFLoader('Jonathan_Pau_Interview_Notes_Detailed.pdf')\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "docsearch = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "retriever = docsearch.as_retriever(\n",
        "    search_type='similarity', search_kwargs={'k':2} # k=2 finds the top 2 most relevant text chunk\n",
        ")     # similarity search retrieves text chunk vectors that ar emost similar to the question\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=OpenAI(),\n",
        "    chain_type='map_reduce', #\n",
        "    retriever=retriever,\n",
        "    return_source_documents=True,\n",
        "    verbose=False\n",
        ")"
      ],
      "metadata": {
        "id": "1Pjj1HyscFbs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa('what are the functions of DE')"
      ],
      "metadata": {
        "id": "m_aeptzLcKNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa('what is newton''s third law')"
      ],
      "metadata": {
        "id": "mu0NRGP5e_Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Colab Inline interface with RAG application"
      ],
      "metadata": {
        "id": "Fq7Nqygke3xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tempfile\n",
        "import panel as pn\n",
        "\n",
        "pn.extension(\"colab\")\n",
        "\n",
        "pdf_input = pn.widgets.FileInput(accept=\".pdf\", value=None, height=50)\n",
        "\n",
        "key_input = pn.widgets.PasswordInput(\n",
        "    name=\"OpenAI Key\",\n",
        "    placeholder=\"Please paste in your OpenAI API key\",\n",
        ")\n",
        "\n",
        "k_slider = pn.widgets.IntSlider(\n",
        "    name=\"Number of Relevant Chunks\", start=1, end=5, step=1, value=2\n",
        ")\n",
        "\n",
        "chain_select = pn.widgets.RadioButtonGroup(\n",
        "    name=\"Chain Type\", options=[\"stuff\", \"map_reduce\", \"refine\", \"map_rerank\"], value=\"stuff\"\n",
        ")\n",
        "\n",
        "chat_input = pn.widgets.TextInput(placeholder=\"Ask a question about the uploaded PDF...\")\n",
        "chat_output = pn.pane.Markdown(\"## The response will appear here.\", sizing_mode=\"stretch_width\")\n",
        "\n",
        "def initialize_chain():\n",
        "    if not key_input.value:\n",
        "        chat_output.object = \"Please provide your OpenAI API Key!\"\n",
        "        return None\n",
        "\n",
        "    os.environ[\"OPENAI_API_KEY\"] = key_input.value\n",
        "\n",
        "    if not pdf_input.value:\n",
        "        chat_output.object = \"Please upload a PDF file.\"\n",
        "        return None\n",
        "\n",
        "    if not chain_select.value:\n",
        "        chat_output.object = \"Please select a chain type.\"\n",
        "        return None\n",
        "\n",
        "    chat_input.placeholder = \"Ask questions here!\"\n",
        "    with tempfile.NamedTemporaryFile(\"wb\", delete=False) as f:\n",
        "        f.write(pdf_input.value)\n",
        "        file_name = f.name\n",
        "\n",
        "    loader = PyPDFLoader(file_name)\n",
        "    documents = loader.load()\n",
        "\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    embeddings = OpenAIEmbeddings()\n",
        "    db = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "    retriever = db.as_retriever(\n",
        "        search_type=\"similarity\", search_kwargs={\"k\": k_slider.value}\n",
        "    )\n",
        "\n",
        "    qa = RetrievalQA.from_chain_type(\n",
        "        llm=OpenAI(),\n",
        "        chain_type=chain_select.value,\n",
        "        retriever=retriever,\n",
        "        return_source_documents=True,\n",
        "        verbose=True,\n",
        "    )\n",
        "\n",
        "    chat_output.object = \"Thinking about this...\"\n",
        "    return qa\n",
        "\n",
        "def on_submit(event=None):\n",
        "    qa_chain = initialize_chain()\n",
        "    if qa_chain:\n",
        "        question = chat_input.value\n",
        "        if question:\n",
        "            response = qa_chain(question)\n",
        "            chat_output.object = (\n",
        "                \"<div style='font-size:20px;'>\"\n",
        "                f\"Answer:\\n{response['result']}\\n\\n\"\n",
        "                #f\"### Source Documents:\\n{[doc.metadata.get('source', 'unknown') for doc in response['source_documents']]}\"\n",
        "                \"</div>\"\n",
        "            )\n",
        "\n",
        "chat_input.param.watch(on_submit, 'value')\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    \"# Mini OpenAI RAG Based PDF Ingesting ChatBot\",\n",
        "    pdf_input,\n",
        "    key_input,\n",
        "    k_slider,\n",
        "    chain_select,\n",
        "    chat_input,\n",
        "    chat_output,\n",
        "    sizing_mode=\"stretch_width\"\n",
        ")\n",
        "\n",
        "dashboard\n"
      ],
      "metadata": {
        "id": "OJgzfpjhnk9K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}